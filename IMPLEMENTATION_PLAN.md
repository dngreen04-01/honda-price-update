# Honda Price Update - Complete Implementation Plan

## Executive Summary

**Current Status**: URL matching bug fixed (0.5% â†’ expected 95%+ matching rate)

**Backend Architecture**: Node.js/TypeScript stack is CORRECT and well-implemented. No changes needed.

**Critical Findings**:
1. âœ… URL canonicalization bug FIXED â†’ matching rate will improve dramatically
2. âš ï¸ Firecrawl is cost-effective at current scale ($0.60-2.40/month) but doesn't scale well
3. âœ… Backend code quality is professional and well-structured
4. â³ Archive functionality is missing (required feature)
5. â³ Parallel processing could improve performance 3x

---

## Phase 1: Immediate Actions (Week 1) ğŸ”¥ CRITICAL

### 1.1 Deploy URL Matching Fix

**Status**: Code changes complete, ready to deploy

**Actions**:
```bash
# 1. Build the updated code
npm run build

# 2. Refresh Shopify catalog cache with canonical URLs
npm run refresh-shopify

# 3. Run scraper to verify matching improvement
npm run scrape

# 4. Check reconciliation results
npm run reconcile
```

**Expected Outcome**: Matching rate increases from 0.5% to 95%+

**Verification**:
- Check logs for "Shopify product cached with canonical URL" messages
- Review reconciliation report for improved matching statistics
- Validate that price syncs are finding products correctly

---

### 1.2 Implement Archive Functionality

**Why**: Required feature for handling discontinued products

**Files to Modify**:
1. `src/database/queries.ts` - Add `archiveProductByUrl()` function
2. `src/shopify/price-sync.ts` - Add `archiveShopifyProducts()` function
3. `src/shopify/client.ts` - Add `updateProductStatus()` method
4. `frontend/src/pages/Dashboard/PriceComparison.tsx` - Add "Archive" button

**Implementation** (estimated 4-6 hours):

```typescript
// src/database/queries.ts
export async function archiveProductByUrl(canonicalUrl: string): Promise<void> {
  const { error } = await supabase
    .from('product_pages')
    .update({
      archived: true,
      archived_at: new Date().toISOString()
    })
    .eq('canonical_url', canonicalUrl);

  if (error) {
    logger.error('Failed to archive product', { error: error.message, canonicalUrl });
    throw error;
  }
}

// src/shopify/client.ts
async updateProductStatus(productId: string, status: 'ACTIVE' | 'ARCHIVED'): Promise<void> {
  const mutation = `
    mutation productUpdate($input: ProductInput!) {
      productUpdate(input: $input) {
        product {
          id
          status
        }
        userErrors {
          field
          message
        }
      }
    }
  `;

  const response = await client.request(mutation, {
    variables: {
      input: {
        id: productId,
        status: status
      }
    }
  });

  // Handle response...
}
```

**Expected Outcome**:
- Database tracks archived products with timestamp
- Shopify products can be set to "ARCHIVED" status
- Frontend shows "Archive" button for discontinued products
- Email notifications include archived product counts

---

### 1.3 Add Monitoring & Alerts

**Why**: Detect issues early before they impact business operations

**Implementation**:

```typescript
// frontend/src/pages/Dashboard/Alerts.tsx
interface AlertThresholds {
  matchingRate: number;  // Minimum acceptable matching rate (e.g., 80%)
  priceChanges: number;  // Maximum acceptable price changes per day
  newProducts: number;   // Alert threshold for new products
}

function checkAlerts(stats: ReconciliationStats): Alert[] {
  const alerts: Alert[] = [];

  const matchingRate = (stats.matched / stats.total) * 100;
  if (matchingRate < 80) {
    alerts.push({
      severity: 'critical',
      message: `Low matching rate: ${matchingRate.toFixed(1)}% (expected >80%)`,
      action: 'Check Shopify metafield population and URL canonicalization'
    });
  }

  return alerts;
}
```

**Expected Outcome**:
- Dashboard shows real-time alert badges
- Email notifications for critical issues
- Matching rate, price changes, and new products monitored

---

## Phase 2: Scraping Optimization (Weeks 2-3)

### 2.1 Migrate to Puppeteer + Bright Data

**Why**: Better cost control, more flexibility, and future-proof solution

**Cost Analysis**:
| Scenario | Firecrawl | Puppeteer + Bright Data | Savings |
|----------|-----------|------------------------|---------|
| Weekly runs (cached) | $0.60-2.40/mo | $5-15/mo | Worth the control |
| Daily runs (cached) | $10-20/mo | $5-15/mo | 50% savings |
| No caching | $100+/mo | $15-20/mo | 80% savings |

**Implementation Plan**:

**Step 1**: Set up Bright Data account
```bash
# Sign up at https://brightdata.com
# Get residential proxy credentials
# Choose "Pay as you go" plan ($10/GB minimum)
```

**Step 2**: Create Puppeteer scraper (estimated 8-12 hours)

```typescript
// src/scraper/puppeteer-scraper.ts
import puppeteer from 'puppeteer';
import { ProxyConfiguration } from 'bright-data-sdk';

export class PuppeteerScraper {
  private browser: Browser | null = null;
  private proxyConfig: ProxyConfiguration;

  constructor() {
    this.proxyConfig = {
      host: process.env.BRIGHT_DATA_HOST,
      port: parseInt(process.env.BRIGHT_DATA_PORT || '22225'),
      username: process.env.BRIGHT_DATA_USERNAME,
      password: process.env.BRIGHT_DATA_PASSWORD,
    };
  }

  async initialize(): Promise<void> {
    this.browser = await puppeteer.launch({
      args: [
        `--proxy-server=${this.proxyConfig.host}:${this.proxyConfig.port}`,
        '--no-sandbox',
        '--disable-setuid-sandbox',
      ],
      headless: true,
    });
  }

  async scrapeProduct(url: string): Promise<{ html: string }> {
    if (!this.browser) {
      throw new Error('Browser not initialized');
    }

    const page = await this.browser.newPage();

    try {
      // Set proxy authentication
      await page.authenticate({
        username: this.proxyConfig.username!,
        password: this.proxyConfig.password!,
      });

      // Navigate with proper waiting
      await page.goto(url, {
        waitUntil: 'networkidle0',
        timeout: 30000,
      });

      // Get HTML content
      const html = await page.content();

      return { html };
    } finally {
      await page.close();
    }
  }

  async batchScrape(urls: string[]): Promise<Map<string, { html: string }>> {
    const results = new Map<string, { html: string }>();

    // Process in parallel batches of 3-5
    const batchSize = 3;
    for (let i = 0; i < urls.length; i += batchSize) {
      const batch = urls.slice(i, i + batchSize);
      const promises = batch.map(async (url) => {
        try {
          const result = await this.scrapeProduct(url);
          results.set(url, result);
        } catch (error) {
          logger.error('Failed to scrape URL', { url, error });
        }
      });

      await Promise.all(promises);

      // Rate limiting - wait 2 seconds between batches
      if (i + batchSize < urls.length) {
        await new Promise((resolve) => setTimeout(resolve, 2000));
      }
    }

    return results;
  }

  async close(): Promise<void> {
    if (this.browser) {
      await this.browser.close();
      this.browser = null;
    }
  }
}
```

**Step 3**: Add Honda-specific selectors for the 3 known domains

```typescript
// src/scraper/honda-selectors.ts
export const hondaSelectors = {
  'hondaoutdoors.co.nz': {
    price: '.product-price .current-price',
    salePrice: '.product-price .sale-price',
    originalPrice: '.product-price .original-price',
    sku: '[data-product-sku]',
    name: '.product-title h1',
  },
  'hondamarine.co.nz': {
    price: '.marine-product-price',
    salePrice: '.sale-price',
    originalPrice: '.compare-price',
    sku: '.product-sku',
    name: '.product-name',
  },
  'hondamotorbikes.co.nz': {
    price: '.bike-price-main',
    salePrice: '.special-price',
    originalPrice: '.regular-price',
    sku: '[data-sku]',
    name: '.bike-title',
  },
};

export function getSelectorsForDomain(url: string): typeof hondaSelectors['hondaoutdoors.co.nz'] | null {
  const domain = extractDomain(url);
  return hondaSelectors[domain as keyof typeof hondaSelectors] || null;
}
```

**Step 4**: Hybrid approach - Firecrawl for mapping, Puppeteer for scraping

```typescript
// src/scraper/scraper-orchestrator.ts
async run(): Promise<void> {
  // Use Firecrawl for site mapping (cheap, one-time per week)
  const urls = await firecrawlClient.mapDomain(domain.root_url);

  // Use Puppeteer for scraping (cost-effective, flexible)
  const puppeteerScraper = new PuppeteerScraper();
  await puppeteerScraper.initialize();

  try {
    const results = await puppeteerScraper.batchScrape(urls);
    // Process results...
  } finally {
    await puppeteerScraper.close();
  }
}
```

**Expected Outcome**:
- $5-15/month cost (predictable)
- 3x faster with parallel batch processing
- Better control over scraping logic
- Honda-specific selectors for 95%+ extraction accuracy

---

### 2.2 Add Parallel Domain Processing

**Why**: Currently processes 3 domains sequentially (2 minutes total). Parallel processing: 40 seconds.

**Implementation** (estimated 2-3 hours):

```typescript
// src/scraper/scraper-orchestrator.ts
async runForAllDomains(): Promise<void> {
  const domains = await getActiveDomains();

  // Before: Sequential (2 minutes)
  // for (const domain of domains) {
  //   await this.runForDomain(domain);
  // }

  // After: Parallel (40 seconds)
  await Promise.all(
    domains.map(domain => this.runForDomain(domain))
  );

  logger.info('Completed scraping for all domains');
}
```

**Expected Outcome**: 3x faster scraping (2 min â†’ 40 sec)

---

### 2.3 Implement Circuit Breaker Pattern

**Why**: Prevent wasting credits on systematic failures

**Implementation** (estimated 3-4 hours):

```typescript
// src/utils/circuit-breaker.ts
export class CircuitBreaker {
  private failureCount = 0;
  private successCount = 0;
  private state: 'CLOSED' | 'OPEN' | 'HALF_OPEN' = 'CLOSED';
  private lastFailureTime: number | null = null;

  constructor(
    private readonly failureThreshold = 5,
    private readonly resetTimeout = 60000 // 1 minute
  ) {}

  async execute<T>(fn: () => Promise<T>): Promise<T> {
    if (this.state === 'OPEN') {
      // Check if enough time has passed to try again
      if (
        this.lastFailureTime &&
        Date.now() - this.lastFailureTime > this.resetTimeout
      ) {
        this.state = 'HALF_OPEN';
        logger.info('Circuit breaker moving to HALF_OPEN state');
      } else {
        throw new Error('Circuit breaker is OPEN - too many failures');
      }
    }

    try {
      const result = await fn();
      this.onSuccess();
      return result;
    } catch (error) {
      this.onFailure();
      throw error;
    }
  }

  private onSuccess(): void {
    this.successCount++;

    if (this.state === 'HALF_OPEN') {
      // Successfully executed in half-open state, close circuit
      this.state = 'CLOSED';
      this.failureCount = 0;
      logger.info('Circuit breaker CLOSED after successful execution');
    }
  }

  private onFailure(): void {
    this.failureCount++;
    this.lastFailureTime = Date.now();

    if (this.failureCount >= this.failureThreshold) {
      this.state = 'OPEN';
      logger.error('Circuit breaker OPEN due to excessive failures', {
        failureCount: this.failureCount,
      });
    }
  }
}

// Usage in scraper-orchestrator.ts
private circuitBreaker = new CircuitBreaker(5, 60000);

async scrapeProducts(urls: string[]): Promise<ScrapedProduct[]> {
  return this.circuitBreaker.execute(async () => {
    // Scraping logic...
  });
}
```

**Expected Outcome**:
- Stop scraping after 5 consecutive failures
- Prevent wasting credits on broken scrapers
- Automatic recovery after 1 minute cooldown

---

## Phase 3: Backend Enhancements (Month 2)

### 3.1 Database-Driven URL Filters

**Why**: Current filters are hardcoded. This requires code deployments to update.

**Implementation**:

```sql
-- Add to database schema
CREATE TABLE url_filters (
  id SERIAL PRIMARY KEY,
  domain_id INT REFERENCES domains(id) ON DELETE CASCADE,
  pattern TEXT NOT NULL,
  type TEXT NOT NULL CHECK (type IN ('exclude', 'include', 'category')),
  priority INT DEFAULT 0,
  active BOOLEAN DEFAULT true,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Example data
INSERT INTO url_filters (domain_id, pattern, type, priority) VALUES
(1, '/cart', 'exclude', 100),
(1, '/checkout', 'exclude', 100),
(1, '/cordless', 'category', 50),
(1, '/generators', 'category', 50);
```

```typescript
// src/database/queries.ts
export async function getUrlFilters(domainId: number): Promise<UrlFilter[]> {
  const { data, error } = await supabase
    .from('url_filters')
    .select('*')
    .eq('domain_id', domainId)
    .eq('active', true)
    .order('priority', { ascending: false });

  if (error) throw error;
  return data as UrlFilter[];
}

// src/scraper/scraper-orchestrator.ts
async discoverProducts(rootUrl: string, domainId: number): Promise<string[]> {
  const filters = await getUrlFilters(domainId);

  const excludePatterns = filters
    .filter(f => f.type === 'exclude')
    .map(f => f.pattern);

  const categoryPatterns = filters
    .filter(f => f.type === 'category')
    .map(f => f.pattern);

  // Use filters in product discovery...
}
```

**Expected Outcome**:
- Update filters via database queries (no code deployment)
- Add UI in dashboard for filter management
- Per-domain filter customization

---

### 3.2 Adaptive Shopify Rate Limiting

**Why**: Current fixed 500ms delay is inefficient. Shopify API returns rate limit info in headers.

**Implementation**:

```typescript
// src/shopify/rate-limiter.ts
export class ShopifyRateLimiter {
  private currentCost = 0;
  private maxCost = 2000; // Shopify limit
  private restoreRate = 100; // Points per second
  private lastRequestTime = Date.now();

  async getDelay(): Promise<number> {
    const now = Date.now();
    const timeSinceLastRequest = now - this.lastRequestTime;

    // Restore points based on time elapsed
    const restoredPoints = (timeSinceLastRequest / 1000) * this.restoreRate;
    this.currentCost = Math.max(0, this.currentCost - restoredPoints);

    // If we're near the limit, wait longer
    if (this.currentCost > this.maxCost * 0.8) {
      return 2000; // 2 second delay when near limit
    } else if (this.currentCost > this.maxCost * 0.5) {
      return 1000; // 1 second delay when at half capacity
    } else {
      return 200; // 200ms delay when plenty of capacity
    }
  }

  updateCost(cost: number): void {
    this.currentCost += cost;
    this.lastRequestTime = Date.now();
  }
}
```

**Expected Outcome**:
- 2-3x faster Shopify API operations when under limit
- Automatic slowdown when approaching rate limit
- Never hit rate limit errors

---

### 3.3 Enhanced Email Notifications

**Why**: Current CSV attachments are not actionable. Users want one-click actions.

**Implementation**:

```typescript
// src/email/templates.ts
export function generatePriceChangeEmail(
  priceChanges: PriceChange[],
  dashboardUrl: string
): string {
  return `
    <html>
      <body>
        <h1>Honda Price Update Report</h1>
        <p>Found ${priceChanges.length} price changes requiring your attention.</p>

        <table style="border-collapse: collapse; width: 100%;">
          <thead>
            <tr>
              <th>Product</th>
              <th>Old Price</th>
              <th>New Price</th>
              <th>Change</th>
              <th>Actions</th>
            </tr>
          </thead>
          <tbody>
            ${priceChanges.map(change => `
              <tr>
                <td>${change.productUrl}</td>
                <td>$${change.oldSalePrice}</td>
                <td>$${change.newSalePrice}</td>
                <td style="color: ${change.changePercent > 0 ? 'red' : 'green'}">
                  ${change.changePercent > 0 ? '+' : ''}${change.changePercent}%
                </td>
                <td>
                  <a href="${dashboardUrl}/review/${encodeURIComponent(change.productUrl)}">
                    Review & Update
                  </a>
                </td>
              </tr>
            `).join('')}
          </tbody>
        </table>

        <p>
          <a href="${dashboardUrl}" style="
            background: #007bff;
            color: white;
            padding: 10px 20px;
            text-decoration: none;
            border-radius: 4px;
          ">View Dashboard</a>
        </p>
      </body>
    </html>
  `;
}
```

**Expected Outcome**:
- Inline HTML email with price comparison table
- One-click links to review/update products in dashboard
- Separate notifications for: price changes, new products, discontinued products
- Summary statistics at the top

---

## Phase 4: Frontend Enhancements (Month 2)

### 4.1 Enhanced Price Comparison View

**File**: `frontend/src/pages/Dashboard/PriceComparison.tsx`

**Features to Add**:
1. Clear display: Supplier Price | Supplier Special | Our Price
2. "Push to Shopify" button (bulk or individual)
3. "Archive Product" button
4. Matching rate statistics dashboard
5. Filter by: price differences, new products, discontinued products

**Mock Design**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Price Comparison Dashboard                                  â”‚
â”‚  Matching Rate: 96.5% (193/200 products)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Filters: [ All ] [ Price Changed ] [ New ] [ Discontinued ] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Product                 Supplier   Special   Our Price   Action â”‚
â”‚  GB350 Bike             $7,999     $7,499    $7,999     [Push] â”‚
â”‚  EU70IS Generator       $4,299     -         $4,299     [âœ“]    â”‚
â”‚  BF20 Outboard         $3,599     $3,299    $3,599     [Push] â”‚
â”‚  (Discontinued Product)  -         -         $2,999     [Archive] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Phase 5: Long-Term Improvements (Months 3-6)

### 5.1 ML-Based Price Change Prediction

**Why**: Scrape products more frequently when price changes are likely

**Implementation** (future):
- Analyze historical price change patterns
- Identify seasonal trends (e.g., specials in December)
- Predict which products likely to have price changes
- Scrape high-priority products daily, others weekly

### 5.2 Multi-Region Support

**Why**: Expand to Australian or US Honda suppliers

**Implementation**:
- Add region field to domains table
- Support multiple currencies (NZD, AUD, USD)
- Region-specific email notifications
- Dashboard filter by region

---

## Deployment Timeline

| Week | Phase | Tasks | Outcome |
|------|-------|-------|---------|
| **Week 1** | Critical Fixes | URL matching fix, archive functionality, monitoring | 95%+ matching rate |
| **Weeks 2-3** | Scraping | Puppeteer migration, parallel processing, circuit breaker | 3x faster, $5-15/mo cost |
| **Week 4** | Backend | Database filters, rate limiting, email templates | Easier maintenance |
| **Month 2** | Frontend | Enhanced dashboard, price comparison UI | Better UX |
| **Months 3+** | Advanced | ML predictions, multi-region support | Future growth |

---

## Technology Stack Validation

### âœ… KEEP Node.js/TypeScript

**Rationale**:
- Shopify GraphQL SDK is Node-first
- Excellent type safety catches bugs at compile time
- Async/await perfect for I/O-bound scraping operations
- Professional code quality already achieved
- No compelling reason to switch languages

**Alternative Considered**: Python (for Scrapy)
- **Rejected**: Would require maintaining two codebases (Node + Python)
- **Rejected**: Shopify SDK support is weaker in Python
- **Rejected**: Scrapy overkill for just 3 domains

### âœ… KEEP Supabase/PostgreSQL

**Rationale**:
- Proper relational schema with foreign keys
- Historical tracking built-in
- Row Level Security for multi-user deployment
- Real-time subscriptions available for dashboard
- Cost-effective for this scale

### âœ… KEEP Frontend (React + Vite)

**Rationale**:
- Modern, fast development experience
- TypeScript integration for type safety
- Good for internal dashboards
- Easy to deploy (Vercel, Netlify, or cloud VM)

---

## Cost Projection

| Component | Current | Optimized | Annual |
|-----------|---------|-----------|--------|
| **Scraping** | $0.60-2.40/mo | $5-15/mo | $60-180 |
| **Database** (Supabase) | $0 (free tier) | $25/mo (pro tier) | $300 |
| **Email** (SendGrid) | $0 (free tier) | $0-15/mo | $0-180 |
| **Hosting** (Cloud VM) | $0 (local) | $5-10/mo | $60-120 |
| **Total** | ~$1/mo | ~$40-65/mo | $420-780/year |

**ROI**: If this system saves 2-4 hours of manual price updates per week, it pays for itself in staff time.

---

## Success Metrics

**Immediate** (Week 1):
- [x] URL matching bug fixed
- [ ] Matching rate 95%+
- [ ] Archive functionality working
- [ ] Build successful with no TypeScript errors

**Short-term** (Month 1):
- [ ] Puppeteer scraper deployed
- [ ] Scraping speed 3x faster (2 min â†’ 40 sec)
- [ ] Monthly cost predictable ($5-15)
- [ ] Circuit breaker preventing failed scrapes

**Long-term** (Months 2-3):
- [ ] Database-driven filters
- [ ] Enhanced email notifications
- [ ] Frontend dashboard with all features
- [ ] Multi-user deployment on cloud server

---

## Next Steps

1. **Deploy URL matching fix** (TODAY)
   ```bash
   npm run build
   npm run refresh-shopify
   npm run scrape
   ```

2. **Implement archive functionality** (This week)

3. **Set up Bright Data account** (Next week)

4. **Migrate to Puppeteer scraper** (Weeks 2-3)

5. **Deploy to cloud server** (Month 2)

---

## Questions & Decisions Needed

1. **Bright Data Account**: Who will manage the Bright Data account and billing?

2. **Email Recipients**: Who should receive price change notifications?

3. **Approval Workflow**: Should price updates require approval before pushing to Shopify, or auto-update?

4. **Scraping Schedule**: Daily? Weekly? Smart scheduling based on ML predictions?

5. **Cloud Deployment**: Which cloud provider? (AWS, Azure, GCP, DigitalOcean, Heroku?)

6. **Budget Approval**: Is $40-65/month budget approved for production deployment?

---

## Conclusion

The Honda Price Update system is **well-architected and production-ready** after the URL matching fix. The recommended path forward is:

1. âœ… **Fix deployed immediately** (URL canonicalization)
2. âš¡ **Quick wins** (archive functionality, monitoring)
3. ğŸš€ **Optimization** (Puppeteer migration, parallel processing)
4. ğŸ“Š **Enhancement** (frontend dashboard, email improvements)

**Expected Timeline**: 3-5 weeks to full optimization, production-ready in 1 week.
